# ğŸ¦ AI Context Vault

**Structure, manage & search your AI work artifacts â€“ across models, with audit trail, via Azure Cloud.**

> AI models can remember. But they can't structure your work into traceable artifacts, search across all sessions, or produce compliance-ready documentation. AI Context Vault can.

[![MIT License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-green.svg)](https://python.org)
[![Azure](https://img.shields.io/badge/Azure-Blob%20%2B%20AI%20Search-0078D4.svg)](https://azure.microsoft.com)

---

## The Problem

Modern AI models have memory, projects, and million-token context windows. **So what's still broken?**

### PD1: ğŸ“‹ Unstructured Artifacts

Your AI work lives as **chat history** â€“ not as manageable artifacts.

After 20 sessions you have hundreds of messages across multiple chats. Decisions, requirements, quality gates â€“ all buried in conversation threads. No IDs, no status tracking, no categories. No way to query "all approved requirements" or "all open quality gates."

> Claude Projects and ChatGPT Memory **remember** your conversations.
> But they don't **structure** them into traceable, queryable artifacts.

### PD2: ğŸï¸ Isolated Knowledge Silos

Each AI model has its own walled garden:

```
Claude Projects    â†’ only accessible in Claude
ChatGPT Memory     â†’ only accessible in ChatGPT
Gemini Workspace   â†’ only accessible in Gemini
```

There is no shared, neutral knowledge layer. If you use Claude for analysis, ChatGPT for writing, and Gemini for data â€“ your knowledge is **fragmented across 3 platforms** with no connection between them.

### PD3: ğŸ“œ No Compliance-Ready Documentation

For regulated projects (EU AI Act, ISO 42001, enterprise audits), you need:
- Versioned artifacts with timestamps and sources
- Traceable decision chains
- Structured evidence documentation

**Chat history is not an audit trail.** No auditor accepts "look at my ChatGPT conversation from 3 months ago" as evidence.

---

## What AI Models Already Solve (and what they don't)

| Capability | AI Models (2026) | AI Context Vault |
|---|:---:|:---:|
| Remember context across sessions | âœ… Projects, Memory | â€“ |
| Large context windows (200Kâ€“1M+) | âœ… Native | â€“ |
| **Structured artifact management** | âŒ Chat history only | âœ… YAML with IDs, status, categories |
| **Cross-model knowledge base** | âŒ Isolated per platform | âœ… Azure Cloud â€“ model-agnostic |
| **Semantic search across ALL sessions** | âŒ Within one project only | âœ… Azure AI Search â€“ full RAG |
| **Compliance-ready audit trail** | âŒ No versioning | âœ… Git-versioned YAML |
| **Progress dashboard** | âŒ No structured overview | âœ… resume.py â†’ âœ…/â¬œ/ğŸ”„ |
| **Enterprise scalability** | âŒ Platform limits | âœ… Azure â€“ unlimited |

---

## The Solution

AI Context Vault adds what AI models are missing:

| Problem | Solution |
|---|---|
| ğŸ“‹ Unstructured Artifacts | Automated extraction â†’ structured YAML with IDs, status, source references |
| ğŸï¸ Isolated Knowledge | Azure Blob Storage + AI Search as neutral, model-agnostic knowledge layer |
| ğŸ“œ No Audit Trail | Git-versioned YAML â†’ traceable, timestamped, diff-able evidence chain |

**Bonus: 98% token savings** â€“ `resume.py` compresses your full project state into ~600 tokens instead of re-loading entire project contexts.

---

## âœ¨ Intelligent Save

Say **"speichern"** (or **"save"**) in your AI chat.
The AI automatically extracts structured artifacts from the conversation:

```mermaid
flowchart LR
    U["ğŸ‘¤ 'speichern'"]
    A["ğŸ¤– Detect context\nchapter, type, topic"]
    Y["ğŸ“„ Generate\nstructured YAML"]
    G["ğŸ“ Route to\ncorrect folder"]
    V["ğŸ”– Git\nversion control"]
    C["â˜ï¸ Azure\nCloud Sync"]

    U --> A --> Y --> G --> V --> C
```

This is not "save the chat." It's:
- **Chat â†’ structured artifact** with ID, status, category, source reference
- **Auto-routing** to the correct project folder based on context
- **Progress tracking** updated automatically in `chapter_state.yaml`
- **Instantly searchable** via Azure AI Search across all sessions

> The difference: AI models remember conversations. This tool **structures them into auditable, searchable artifacts.**

---

## ğŸ”„ Architecture & Workflow

```mermaid
flowchart TB
    subgraph LOCAL["ğŸ–¥ï¸ Local Machine"]
        direction TB
        GIT["ğŸ“ Git Repository\n(YAML + Markdown artifacts)"]
        CHAT["ğŸ’¬ AI Chat Session\n(Claude, ChatGPT, etc.)"]
    end

    subgraph AZURE["â˜ï¸ Azure Cloud"]
        direction TB
        BLOB["ğŸ“¦ Blob Storage\nAll artifacts versioned"]
        SEARCH["ğŸ” AI Search Index\nFull-text + semantic search"]
    end

    subgraph SCRIPTS["âš¡ CLI Toolkit"]
        direction TB
        S1["resume.py\nğŸ“‹ Progress dashboard\n~600 tokens"]
        S2["reindex.py\nâ˜ï¸ Sync to Azure\n$0 cost"]
        S3["search.py\nğŸ” Cross-session RAG\nAzure + Claude"]
        S4["extract_yamls.py\nğŸ§  Intelligent Save\nChat â†’ structured YAML"]
    end

    CHAT -->|"Work in AI session"| GIT
    GIT -->|"reindex.py"| BLOB
    BLOB -->|"auto-index"| SEARCH
    SEARCH -->|"search.py"| CHAT
    GIT -->|"resume.py"| CHAT
    CHAT -->|"'speichern'"| S4
    S4 -->|"structured artifacts"| GIT

    style LOCAL fill:#f8f9fc,stroke:#1a2744,stroke-width:2px
    style AZURE fill:#e8f4fd,stroke:#0078D4,stroke-width:2px
    style SCRIPTS fill:#f0fdf4,stroke:#22c55e,stroke-width:2px
```

### Workflow Step-by-Step

```mermaid
sequenceDiagram
    participant User
    participant AI as AI Model (any)
    participant Scripts as CLI Scripts
    participant Azure as Azure Cloud

    Note over User,Azure: ğŸŸ¢ START NEW SESSION
    User->>Scripts: python3 resume.py
    Scripts->>Scripts: Parse YAML artifacts â†’ progress dashboard
    Scripts-->>User: ğŸ“‹ ~600 token structured context (clipboard)
    User->>AI: Paste context + new question

    Note over User,Azure: ğŸ’¬ WORK IN SESSION
    User->>AI: Discuss, iterate, create
    AI-->>User: Answers, artifacts, decisions

    Note over User,Azure: ğŸ’¾ INTELLIGENT SAVE
    User->>AI: "speichern" / "save"
    AI->>AI: Detect chapter, topic & artifact type
    AI->>Scripts: Auto-extract structured YAML
    Scripts->>Scripts: Route to correct folder + update progress
    Scripts-->>User: âœ… R007.yaml â†’ 04_anforderungsanalyse/requirements/

    Note over User,Azure: â˜ï¸ SYNC TO CLOUD
    User->>Scripts: python3 reindex.py
    Scripts->>Azure: Upload artifacts â†’ Blob Storage
    Scripts->>Azure: Index documents â†’ AI Search

    Note over User,Azure: ğŸ” CROSS-SESSION RAG QUERY
    User->>Scripts: python3 search.py "my question"
    Scripts->>Azure: Azure AI Search (Top-8 across ALL sessions)
    Azure-->>Scripts: Relevant artifacts
    Scripts->>AI: Claude RAG analysis
    AI-->>User: Grounded answer with sources
```

---

## ğŸš€ Quick Start

### 1. Clone & Install

```bash
git clone https://github.com/MustDemir/ai-context-vault.git
cd ai-context-vault
pip install -r requirements.txt
cp .env.example .env
# Edit .env with your credentials
```

### 2. Setup Azure Resources

```bash
# Create Azure AI Search index
python3 scripts/create_index.py
```

<details>
<summary>ğŸ“‹ Azure Setup Guide (click to expand)</summary>

**What you need:**
- Azure account (free tier works!)
- Storage Account (Blob Storage)
- Azure AI Search service (free tier: 50MB, 3 indexes)

**Steps:**
1. Create a Storage Account â†’ note the name + key
2. Create an Azure AI Search service â†’ note the endpoint + key
3. Copy `.env.example` to `.env` and fill in credentials
4. Run `python3 scripts/create_index.py` to create the search index

</details>

### 3. Daily Workflow

```bash
# âœ¨ INTELLIGENT SAVE (primary workflow)
# Say "speichern" or "save" in your AI chat
# â†’ AI extracts structured YAML artifacts automatically

# ğŸ“‹ Resume a session (structured progress dashboard â†’ clipboard)
python3 scripts/resume.py

# ğŸ“‹ Resume specific chapter only
python3 scripts/resume.py 04

# â˜ï¸ Sync all artifacts to Azure
python3 scripts/reindex.py

# ğŸ” Search across ALL sessions and artifacts
python3 scripts/search.py "what are the compliance requirements?"

# ğŸ¤– Manual artifact extraction (fallback)
python3 scripts/extract_yamls.py --input chat.txt --type requirements
python3 scripts/extract_yamls.py --input chat.txt --type gates
```

---

## ğŸ“Š Token Efficiency

While modern AI models support large context windows, loading full project contexts is wasteful and expensive at scale:

| Approach | Tokens per Session | 10 Sessions | Cost (Claude) |
|---|---:|---:|---:|
| âŒ Load full project context | ~30,000 | 300,000 | ~$4.50 |
| âŒ Re-explain everything | ~15,000 | 150,000 | ~$2.25 |
| âœ… **resume.py** (structured dashboard) | **~600** | **6,000** | **~$0.09** |

Token savings become critical at **enterprise scale** (teams Ã— sessions Ã— days).

---

## ğŸ—‚ï¸ Project Structure

```
ai-context-vault/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ resume.py           # ğŸ“‹ Structured progress dashboard
â”‚   â”œâ”€â”€ reindex.py          # â˜ï¸ Sync to Azure (Blob + Search)
â”‚   â”œâ”€â”€ search.py           # ğŸ” Cross-session RAG query
â”‚   â”œâ”€â”€ extract_yamls.py    # ğŸ§  Intelligent Save engine
â”‚   â””â”€â”€ create_index.py     # ğŸ—ï¸ Azure Search index setup
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ yaml_templates/     # Example YAML templates
â”‚       â”œâ”€â”€ requirement_template.yaml
â”‚       â”œâ”€â”€ gate_template.yaml
â”‚       â””â”€â”€ chapter_state_template.yaml
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ ARCHITECTURE.md     # Design decisions & architecture
â”œâ”€â”€ .env.example            # Environment template (no secrets!)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## ğŸ”§ How Each Script Works

### `resume.py` â€“ Structured Progress Dashboard ğŸ“‹

```
Input:  Your local YAML/MD files (Git repo)
Output: ~600 token progress dashboard â†’ clipboard

Pipeline:
1. Scan chapter_state.yaml    â†’ chapter progress
2. Scan requirement YAMLs     â†’ R001-R00n with status
3. Scan gate YAMLs            â†’ gate completion per dimension
4. Compile structured summary â†’ icons (âœ…/â¬œ/ğŸ”„)
5. Auto-copy to clipboard     â†’ paste into any AI model

Token cost: $0 (no API calls, pure local parsing)
```

### `reindex.py` â€“ Azure Cloud Sync â˜ï¸

```
Input:  Your local YAML/MD files
Output: Files in Azure Blob + indexed in Azure AI Search

Pipeline:
1. Find all .yaml/.yml/.md    â†’ recursive scan
2. Upload to Blob Storage     â†’ versioned artifacts
3. Create search documents    â†’ metadata extraction
4. Batch upsert to Search     â†’ retry/backoff for 429
5. SHA1-based IDs             â†’ idempotent (safe re-run)

Token cost: $0 (Azure SDK only, no AI calls)
```

### `search.py` â€“ Cross-Session RAG Engine ğŸ”

```
Input:  Natural language question
Output: AI answer grounded in artifacts from ALL sessions

Pipeline:
1. Azure AI Search query      â†’ Top-8 across entire knowledge base
2. Assemble context           â†’ from retrieved artifacts
3. Send to Claude API         â†’ with source references
4. Return grounded answer     â†’ [1], [2] citations

vs. Claude Projects: searches only within ONE project
vs. AI Context Vault: searches across ALL sessions, chapters, artifact types

Token cost: ~$0.01-0.05 per query
```

### `extract_yamls.py` â€“ Intelligent Save Engine ğŸ§ 

```
Primary:  Say "speichern" in chat â†’ fully automatic
Fallback: python3 scripts/extract_yamls.py --input chat.txt

Pipeline:
1. Detect context             â†’ chapter, topic, artifact type
2. Check existing IDs         â†’ prevent duplicates
3. Claude API extraction      â†’ conversation â†’ structured JSON
4. Parse + save as YAML       â†’ correct project folder with ID + status
5. Update chapter_state.yaml  â†’ progress_pct, artifacts_count
6. Git-ready artifacts        â†’ versionable, auditable, diff-able

Token cost: ~$0.05-0.20 per extraction
```

---

## ğŸŒ Cross-Model Compatibility

AI Context Vault is **model-agnostic by design**. Azure Cloud serves as the neutral knowledge layer:

| Model | How to Use |
|---|---|
| **Claude** | Paste `resume.py` output â†’ continue working |
| **ChatGPT** | Paste `resume.py` output â†’ continue working |
| **Gemini** | Paste `resume.py` output â†’ continue working |
| **Local LLMs** (Ollama, etc.) | Paste `resume.py` output â†’ continue working |
| **Any future model** | Paste `resume.py` output â†’ continue working |

Unlike platform-specific Projects or Memory features, your artifacts live in **your** Azure subscription â€“ independent of any AI vendor.

---

## ğŸ—ï¸ Azure Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Azure Cloud                      â”‚
â”‚          (neutral, model-agnostic layer)          â”‚
â”‚                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Blob Storage      â”‚  â”‚  AI Search           â”‚ â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”‚ â”‚
â”‚  â”‚  ğŸ“„ YAML artifacts â”‚â”€â”€â”‚  ğŸ” Full-text search â”‚ â”‚
â”‚  â”‚  ğŸ“„ MD docs        â”‚  â”‚  ğŸ” Semantic ranking â”‚ â”‚
â”‚  â”‚  ğŸ“„ Evidence chain â”‚  â”‚  ğŸ” Cross-session    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â†‘                        â†“                â”‚
â”‚     reindex.py               search.py            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†‘                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Local Machine                       â”‚
â”‚                                                   â”‚
â”‚  ğŸ“ Git repo â”€â”€â†’ resume.py â”€â”€â†’ ğŸ“‹ Any AI model   â”‚
â”‚       â†‘                            â†“              â”‚
â”‚  "speichern" â†â”€â”€ ğŸ’¬ AI Chat Session               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¡ Use Cases

- **ğŸ§  Intelligent Save** â€“ Say "save" â†’ AI extracts structured YAML, routes to correct folder, updates progress
- **ğŸ“š Thesis / Research Management** â€“ Track requirements, gates, progress across chapters and sessions
- **ğŸ¢ Enterprise AI Projects** â€“ Shared knowledge base across teams and AI models via Azure
- **âš–ï¸ Compliance Documentation** â€“ EU AI Act / ISO 42001: Git-versioned evidence chain
- **ğŸ” Cross-Session Search** â€“ RAG across ALL your AI work, not just the current project
- **ğŸ”¬ Any Long-Running AI Project** â€“ Structured artifact management at scale

---

## ğŸ¤ Contributing

Contributions welcome! Please open an issue or pull request.

## ğŸ“„ License

MIT License â€“ see [LICENSE](LICENSE)

## ğŸ‘¤ Author

**Mustafa Demir** â€“ SRH Fernhochschule, M.Sc. Digital Management & Transformation

[![GitHub](https://img.shields.io/badge/GitHub-MustDemir-181717?style=flat&logo=github)](https://github.com/MustDemir)

---

*Built with Azure AI Search, Claude API, and Python. AI models remember conversations â€” this tool structures them into auditable, searchable, cross-model artifacts.*
